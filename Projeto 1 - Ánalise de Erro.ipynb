{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto de Análise de Erro\n",
    "\n",
    "Esse projeto busca abordar erros associados a representação computacional de ponto flutuante, na execução de operações de produto interno de vetores N-dimensionais. Para fins de análise, utilizaremos o protudo interno usual definido abaixo:\n",
    "\n",
    "\\begin{equation}\n",
    "<X, Y> = \\sum_{i=1}^{n} x_i y_i = x_1 y_1 + x_2 y_2 + ... + x_n y_n\n",
    "\\end{equation}\n",
    "\n",
    "Para realizarmos o estudo do impacto do erro de máquina sobre esta operação, desvemos possuir um valor alvo esperado, esse valor ideal representa o resultado desejado ao final da operação, onde a diferença entre o valor real obtido e o valor ideal é o erro gerado durante sua execução. Para obter esse valor ideal, iremos considerar que os vetores nessa análise estão normalizados, isso é, para todo vetor $X$, sua norma é iqual a $1$, logo:\n",
    "\n",
    "\\begin{equation}\n",
    "||X|| = \\sqrt{<X, X>} = <X, X> = 1\n",
    "\\end{equation}\n",
    "\n",
    "Com o objetivo de definir um escopo mais restrito ao projeto, também iremos considerar que todos os vetores são binários, isso é, para todo vetor $X$, $x_i = 0$ ou $x_i = k$, onde $0 <= i < N$ e $k \\in R$. Vale resaltar que este tipo de configuração de vetores é bem comum para representação de dados, como palavras, textos, documentos, taxonomias, classificação, etc.\n",
    "\n",
    "Este projeto será execultado na linguagem C/C++, perminitindo interpretar mais facilmente os problemas associados aos bits, além disso será ultilizado a representação de ponto flutuante com menor precisão em C/C++, neste caso o \"_float_\", trata-se de uma representação padronizada pela _IEEE_ com 32 bits nomeada de _single_ (a representação de 16 bits (_half_) não é nativa em C/C++). Por padrão, C/C++ utiliza truncamento na adminstração de dados.\n",
    "\n",
    "Resumindo, teremos:\n",
    "\n",
    "> - Operação de produto interno como alvo da ánalise de erro.\n",
    "> - Todos os vetores que envolvem o problema possuem norma 1, a norma será o valor esperado do produto interno.\n",
    "> - Todos os vetores são binários, possuindo apenas dois valores possíveis em cada dimensão, reduzindo o escopo do problema.\n",
    "> - Representação _float_ em C/C++ com 32 bits de precisão com trucamento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procedimentos Iniciais\n",
    "\n",
    "Para analizar os dados visualmente, iremos importar as bibliotecas gráficas utilizadas no jupyter e no interpretador de C/C++, neste caso, o Xplot da Xeus, que usa como base o bgplot em Python. Também seram iniciados as estruturas de dados padrão que seram utilizadas durante toda a análise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#include \"xplot/xfigure.hpp\"\n",
    "#include \"xplot/xmarks.hpp\"\n",
    "#include \"xplot/xaxes.hpp\"\n",
    "#include <iostream>\n",
    "\n",
    "using namespace std;\n",
    "\n",
    "float maximum = 0.0f;\n",
    "vector<double> x;\n",
    "vector<double> y;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementação Singela de Produto Interno\n",
    "\n",
    "Como desejamos simular o produto interno para uma situação muito especifica, isso é, para vetores binários normalizados aplicados a relação $<X, X> = 1$, podemos partir do principio de algumas otimizações que não impactam na implementação singela de produto interno, tais como:\n",
    "\n",
    "> - Produto interno é indiferente quanto a dimensões nulas, podendo ser retiradas da operação.\n",
    "> - A dimensão do vetor é irrelevante, desde que o número de dimensões não-nulas seja informado.\n",
    "> - não é necessario a costrução de uma estrutura de array para representação do vetor, por ele ser binário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "float dotNaive(int size, int shift=0){\n",
    "    float max = 0.0f;\n",
    "    x = vector<double>(size);\n",
    "    y = vector<double>(size);\n",
    "    x[0] = 0; y[0] = 1.0;\n",
    "    for(int i=1 ; i<size ; i++){\n",
    "        int aux = i << shift;\n",
    "        float d = 1.0 / sqrt(aux);\n",
    "        float sum = 0.0f;\n",
    "        for(int j=0 ; j<aux ; j++){\n",
    "            sum += d*d;\n",
    "        }\n",
    "        if(max < sum){\n",
    "            max = sum;\n",
    "        }\n",
    "        x[i] = aux;\n",
    "        y[i] = sum;\n",
    "    }\n",
    "    return max;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primeiro teste de execução\n",
    "\n",
    "Iremos executar o código para gerar o resultado dos 10000 primeiros vetores com dimensão não-nula até 10000, o resultado segue no gráfico abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "112eb694b4e34230a4b8bba40fc2adec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter widget"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dotNaive(10000);\n",
    "xpl::linear_scale sx1, sy1;\n",
    "auto fig1 = xpl::figure_generator().padding_x(0.025).padding_y(0.025).finalize();\n",
    "fig1.add_mark(xpl::scatter_generator(sx1, sy1).x(x).y(y).default_size(1).finalize());\n",
    "fig1.add_axis(xpl::axis_generator(sy1).label(\"Valor Obtido\").orientation(\"vertical\").side(\"left\").finalize());\n",
    "fig1.add_axis(xpl::axis_generator(sx1).label(\"Número de Dimensões Não-Nulas\").finalize());\n",
    "fig1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise de resultados \n",
    "\n",
    "Do gráfico acima podemos observar que ocorreu grande dispersão do valor com relação ao valor esperado, observe também que o erro associado cresce significativamente conforme o número de dimensões não-nulas crescem, demostrando uma forte correlação desta caracteristica com o erro. Observe tambem que o erro parece ser mais intenso em duas regioes especificas demostrando uma configuração \"bimodal\", sendo menos intenso com valores proximos ao ideial, e menos recorrente nos erros extremos, contudo elevado nos valores de erro medio absoluto. Observe também que o gráfico aparenta demostrar determinados padrões de frequência, como pequenas senoídes, irremos ataca esse padrão de forma a evidencia-lo e demostrar suas características, para isso iremos aplica o produto vetorial em vetores com potencias de 2 elementos não-nulos afim de reforçar a ocorrência do padrão. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cc084fdbd794eac9b8368f51125aa40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter widget"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dotNaive(10000, 8);\n",
    "xpl::linear_scale sx2, sy2;\n",
    "auto fig2 = xpl::figure_generator().padding_x(0.025).padding_y(0.025).finalize();\n",
    "fig2.add_mark(xpl::scatter_generator(sx2, sy2).x(x).y(y).default_size(1).finalize());\n",
    "fig2.add_axis(xpl::axis_generator(sy2).label(\"Valor Obtido\").orientation(\"vertical\").side(\"left\").finalize());\n",
    "fig2.add_axis(xpl::axis_generator(sx2).label(\"Número de Dimensões Não-Nulas\").finalize());\n",
    "fig2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotNaive(200, 23);\n",
    "xpl::linear_scale sx3, sy3;\n",
    "auto fig3 = xpl::figure_generator().padding_x(0.025).padding_y(0.025).finalize();\n",
    "fig3.add_mark(xpl::scatter_generator(sx3, sy3).x(x).y(y).default_size(1).finalize());\n",
    "fig3.add_axis(xpl::axis_generator(sy3).label(\"Valor Obtido\").orientation(\"vertical\").side(\"left\").finalize());\n",
    "fig3.add_axis(xpl::axis_generator(sx3).label(\"Número de Dimensões Não-Nulas\").finalize());\n",
    "fig3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que os problemas aparentam demostrar certo padrão, ficando mais evindente quanto colocamos o valor da manquisa (23 bits) como valor do passo, fazendo com que os problemas recaiam sobre o expoente (8 bits). Contudo devemos observar essa observação com cautela, pois ele pode evidência problemas de subamostragem, intuido padrãoes que podem não necessariamente existir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estudo da distribuição do erro\n",
    "Iremos contruir o histograma sobre o erro absoluto obtido a fim de identificar o comportamento assocido a ele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f137d064452b415bbd789c9f8d7a83c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter widget"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maximum = dotNaive(10000);\n",
    "xpl::linear_scale sx4, sy4;\n",
    "xpl::hist hist(sx4, sy4);\n",
    "for(int i=0 ; i<y.size() ; i++){\n",
    "    y[i] = abs(1 - y[i]);\n",
    "}\n",
    "hist.sample = y;\n",
    "xpl::figure fig4;\n",
    "fig4.add_mark(hist);\n",
    "xpl::axis hx(sx4), hy(sy4);\n",
    "hy.orientation = \"vertical\";\n",
    "fig4.add_axis(hx);\n",
    "fig4.add_axis(hy);\n",
    "hist.colors = std::vector<std::string>{\"21c0fc\"};\n",
    "fig4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos observar o erro apresenta comportamento exponencial. Contudo, devemos resaltar que esse resultado tambem pode esta tendendioso por consequência da subamostragem que foi execultada (10000 vetores)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Causas do problema\n",
    "O problema acontece principalmente por dois motivos:\n",
    "> - O primeiro motivo são os erros proveniente da normalização numérica, gerando problemas com arredondamento / truncamento na representação. Casos de dizimas periódicas que podem ser arredondadas são bons exemplos desse erro ($1/3 = 0.3333334$).\n",
    "> - O segundo caso é um erro de operação gerado pelo somatório sequêncial. Realizamos duas operação ao calcular o produto interno de um vetor, isso é, a multiplicação de um elemento por ele mesmo (potência de 2) e a soma de todos essas potências. Como sabemos que o vetor é normalizado, teremos que os valores dos elementos variam no intervalo $[1, 0]$, isso faz com que a potência de 2 de um dado elemento no valor $x$ produza um número menor ou igual a $x$, contudo esses valores tendem as ser muito pequenos, pois normalmente $x <<< 1$, fazendo com que $x^2 <<< x$. Até então isso não geraria problema algum, se não fosse a soma sequêncial de valores, a cada potência que realizamos, somamos o valor obtido em um valor total $t$ que retorna a resposta do somatório, contudo, conforme $t$ tende ao valor de $1$ da norma, o valor de $x^2$ deixa de impactar na soma por $x^2 <<< 1$, causando o surgimento de erros de operação. Isso é, o valor do resultado da potência, deixa de fazer impacto sobre a soma total.\n",
    "\n",
    "![title](imagens/lista.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solução para minimização do erro\n",
    "Dentre os problemas que podemos atacar, iremos resaltar o segundo, pois os erros ligados a arredondamento / truncamento de dados, tendem a soluções com representações complexa de estruturas, que não desejamos atacar no contexto desse projeto, nesse caso desejamos minimizar os erros ligados a operação de soma sequêncial. Sendo assim, precisamos garantir que valores pequenos não sejam desprezados com relação a soma de valores grandes, isso pode ser contornado com o uso de uma soma distribuida, que realiza pequenos somatórios somatórios, e posteriormente, acumula em somatórios maiores como pode ser descrito na árvore abaixo:\n",
    "\n",
    "![title](imagens/arvore.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "float sumDist(float num, int bgn, int end){\n",
    "    if(bgn == end-1){\n",
    "        return num;\n",
    "    }\n",
    "    int hlf = (bgn + end)/2;\n",
    "    return sumDist(num, bgn, hlf) + sumDist(num, hlf, end);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "float dot(int size, int shift=0){\n",
    "    float max = 0.0f;\n",
    "    x = vector<double>(size);\n",
    "    y = vector<double>(size);\n",
    "    x[0] = 0; y[0] = 1.0;\n",
    "    for(int i=1 ; i<size ; i++){\n",
    "        int aux = i << shift;\n",
    "        float d = 1.0 / sqrt(aux);\n",
    "        float sum = sumDist(d*d, 0, i);\n",
    "        if(max < sum){\n",
    "            max = sum;\n",
    "        }\n",
    "        x[i] = aux;\n",
    "        y[i] = sum;\n",
    "    }\n",
    "    return max;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "010f9d3cd01b45ca98ae81eae167cb5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter widget"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot(10000);\n",
    "xpl::linear_scale sx5, sy5;\n",
    "auto fig5 = xpl::figure_generator().padding_x(0.025).padding_y(0.025).finalize();\n",
    "fig5.add_mark(xpl::scatter_generator(sx5, sy5).x(x).y(y).default_size(1).finalize());\n",
    "fig5.add_axis(xpl::axis_generator(sy5).label(\"Valor Obtido\").orientation(\"vertical\").side(\"left\").finalize());\n",
    "fig5.add_axis(xpl::axis_generator(sx5).label(\"Número de Dimensões Não-Nulas\").finalize());\n",
    "fig5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos observar, o erro ainda existe, contudo nesta nova abordagem, visualizamos apenas erros provenientas da operação de normalização, se tornando mais regular. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62f6f183298342209c6aa6ff8b98194d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter widget"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xpl::linear_scale sx7, sy7;\n",
    "xpl::hist hist2(sx7, sy7);\n",
    "for(int i=0 ; i<y.size() ; i++){\n",
    "    y[i] = abs(1 - y[i]);\n",
    "}\n",
    "hist2.sample = y;\n",
    "xpl::figure fig7;\n",
    "fig7.add_mark(hist2);\n",
    "xpl::axis hx2(sx4), hy2(sy4);\n",
    "hy2.orientation = \"vertical\";\n",
    "fig7.add_axis(hx2);\n",
    "fig7.add_axis(hy2);\n",
    "hist2.colors = std::vector<std::string>{\"21c0fc\"};\n",
    "fig7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A regularidade do erro se torna ainda mais evidente na visualização do histograma acima, que apresenta uma distribuição muito especifica com relação ao problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f35199e0fd0341c6857d3ff0385cd70f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter widget"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot(10000);\n",
    "y[y.size()-1] = maximum;\n",
    "y[y.size()-2] = 2.0f - maximum;\n",
    "xpl::linear_scale sx6, sy6;\n",
    "auto fig6 = xpl::figure_generator().padding_x(0.025).padding_y(0.025).finalize();\n",
    "fig6.add_mark(xpl::scatter_generator(sx6, sy6).x(x).y(y).default_size(1).finalize());\n",
    "fig6.add_axis(xpl::axis_generator(sy6).label(\"Valor Obtido\").orientation(\"vertical\").side(\"left\").finalize());\n",
    "fig6.add_axis(xpl::axis_generator(sx6).label(\"Número de Dimensões Não-Nulas\").finalize());\n",
    "fig6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observamos a disposisão dos dados sobre a mesma escala, podemos analizar que ocorreu redução significativa do erro com relação a abordagem singela "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "C++14",
   "language": "C++14",
   "name": "xeus-cling-cpp14"
  },
  "language_info": {
   "codemirror_mode": "text/x-c++src",
   "file_extension": ".cpp",
   "mimetype": "text/x-c++src",
   "name": "c++",
   "version": "-std=c++14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
